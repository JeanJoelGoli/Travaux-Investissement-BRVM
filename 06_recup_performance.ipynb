{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b2a86e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä ABJC ...\n",
      "üìä BICB ...\n",
      "üìä BICC ...\n",
      "üìä BNBC ...\n",
      "üìä BOAB ...\n",
      "üìä BOABF ...\n",
      "üìä BOAC ...\n",
      "üìä BOAM ...\n",
      "üìä BOAN ...\n",
      "üìä BOAS ...\n",
      "üìä CABC ...\n",
      "üìä CBIBF ...\n",
      "üìä CFAC ...\n",
      "üìä CIEC ...\n",
      "üìä ECOC ...\n",
      "üìä ETIT ...\n",
      "üìä FTSC ...\n",
      "üìä LNBB ...\n",
      "üìä NEIC ...\n",
      "üìä NSBC ...\n",
      "üìä NTLC ...\n",
      "üìä ONTBF ...\n",
      "üìä ORAC ...\n",
      "üìä ORGT ...\n",
      "üìä PALC ...\n",
      "üìä PRSC ...\n",
      "üìä SAFC ...\n",
      "üìä SCRC ...\n",
      "üìä SDCC ...\n",
      "üìä SDSC ...\n",
      "üìä SEMC ...\n",
      "üìä SGBC ...\n",
      "üìä SHEC ...\n",
      "üìä SIBC ...\n",
      "üìä SICC ...\n",
      "üìä SIVC ...\n",
      "üìä SLBC ...\n",
      "üìä SMBC ...\n",
      "üìä SNTS ...\n",
      "üìä SOGC ...\n",
      "üìä SPHC ...\n",
      "üìä STAC ...\n",
      "üìä STBC ...\n",
      "üìä SVOC ...\n",
      "üìä TTLC ...\n",
      "üìä TTLS ...\n",
      "üìä UNLC ...\n",
      "üìä UNXC ...\n",
      "‚úÖ Fichier g√©n√©r√© : valorisation_performances.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from playwright.async_api import async_playwright\n",
    "\n",
    "TICKERS = [\n",
    "    \"ABJC\",\"BICB\",\"BICC\",\"BNBC\",\"BOAB\",\"BOABF\",\"BOAC\",\"BOAM\",\"BOAN\",\"BOAS\",\n",
    "    \"CABC\",\"CBIBF\",\"CFAC\",\"CIEC\",\"ECOC\",\"ETIT\",\"FTSC\",\"LNBB\",\"NEIC\",\"NSBC\",\n",
    "    \"NTLC\",\"ONTBF\",\"ORAC\",\"ORGT\",\"PALC\",\"PRSC\",\"SAFC\",\"SCRC\",\"SDCC\",\"SDSC\",\n",
    "    \"SEMC\",\"SGBC\",\"SHEC\",\"SIBC\",\"SICC\",\"SIVC\",\"SLBC\",\"SMBC\",\"SNTS\",\"SOGC\",\n",
    "    \"SPHC\",\"STAC\",\"STBC\",\"SVOC\",\"TTLC\",\"TTLS\",\"UNLC\",\"UNXC\"\n",
    "]\n",
    "\n",
    "UA = (\"Mozilla/5.0 (Macintosh; Intel Mac OS X 14_6) AppleWebKit/537.36 \"\n",
    "      \"(KHTML, like Gecko) Chrome/126.0 Safari/537.36\")\n",
    "\n",
    "def clean_num(x: str) -> str:\n",
    "    if not x:\n",
    "        return \"\"\n",
    "    x = re.split(r\"\\(\", x)[0]\n",
    "    x = x.replace(\"%\", \"\")\n",
    "    x = x.replace(\"\\xa0\", \" \").replace(\" \", \"\")\n",
    "    x = x.replace(\",\", \".\")\n",
    "    x = x.strip()\n",
    "    if x in {\"-\", \"‚Äì\", \"‚Äî\"}:\n",
    "        return \"\"\n",
    "    return x\n",
    "\n",
    "def norm_text(s: str) -> str:\n",
    "    # normalise espaces et apostrophe typographique\n",
    "    return s.replace(\"\\xa0\", \" \").replace(\"\\u2019\", \"'\").strip()\n",
    "\n",
    "def parse_all_tables(html: str) -> list[pd.DataFrame]:\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    dfs = []\n",
    "    for tbl in soup.find_all(\"table\"):\n",
    "        thead = tbl.find(\"thead\")\n",
    "        headers = [norm_text(th.get_text(strip=True)) for th in thead.find_all(\"th\")] if thead else []\n",
    "        tbody = tbl.find(\"tbody\")\n",
    "        if not tbody: \n",
    "            continue\n",
    "        rows = []\n",
    "        for tr in tbody.find_all(\"tr\"):\n",
    "            tds = [norm_text(td.get_text(\" \", strip=True)) for td in tr.find_all([\"td\",\"th\"])]\n",
    "            if tds:\n",
    "                rows.append(tds)\n",
    "        if not rows:\n",
    "            continue\n",
    "        if not headers:\n",
    "            headers = [norm_text(c) for c in rows[0]]\n",
    "            rows = rows[1:]\n",
    "        w = min(len(headers), max((len(r) for r in rows), default=0))\n",
    "        if w == 0:\n",
    "            continue\n",
    "        headers = headers[:w]\n",
    "        rows = [r[:w] for r in rows]\n",
    "        try:\n",
    "            dfs.append(pd.DataFrame(rows, columns=headers))\n",
    "        except Exception:\n",
    "            continue\n",
    "    return dfs\n",
    "\n",
    "async def robust_goto(page, url: str):\n",
    "    await page.goto(url, timeout=60000)\n",
    "    await page.wait_for_load_state(\"domcontentloaded\")\n",
    "    if \"/investisseur/profile\" in page.url:\n",
    "        await page.goto(url, timeout=60000)\n",
    "        await page.wait_for_load_state(\"domcontentloaded\")\n",
    "    try:\n",
    "        await page.wait_for_load_state(\"networkidle\", timeout=10000)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# -------- VALORISATION (historique seulement) --------\n",
    "async def scrape_valorisation_histo(page, ticker: str) -> pd.DataFrame:\n",
    "    url = f\"https://www.richbourse.com/investisseur/analyse-societe/valorisation/{ticker}\"\n",
    "    await robust_goto(page, url)\n",
    "    html = await page.content()\n",
    "    dfs = parse_all_tables(html)\n",
    "    if not dfs:\n",
    "        return pd.DataFrame()\n",
    "    target = None\n",
    "    for df in dfs:\n",
    "        cols = set(df.columns)\n",
    "        if \"Ann√©e\" in cols and ({\"PER Action\",\"PER Secteur\",\"PBR Action\",\"PBR Secteur\"} & cols):\n",
    "            target = df.copy()\n",
    "            break\n",
    "    if target is None:\n",
    "        return pd.DataFrame()\n",
    "    keep = [c for c in [\"Ann√©e\",\"PER Action\",\"PER Secteur\",\"PBR Action\",\"PBR Secteur\"] if c in target.columns]\n",
    "    target = target[keep]\n",
    "    for c in [k for k in keep if k != \"Ann√©e\"]:\n",
    "        target[c] = target[c].map(clean_num)\n",
    "    target[\"Ticker\"] = ticker\n",
    "    return target\n",
    "\n",
    "# -------- PERFORMANCES (cliquer l‚Äôonglet ROE, Gearing, etc.) --------\n",
    "async def scrape_performances(page, ticker: str) -> pd.DataFrame:\n",
    "    url = f\"https://www.richbourse.com/investisseur/analyse-societe/performances-ratios/{ticker}\"\n",
    "    await robust_goto(page, url)\n",
    "\n",
    "    # clique explicitement sur l‚Äôonglet ‚ÄúROE, Gearing, etc.‚Äù\n",
    "    try:\n",
    "        await page.get_by_text(\"ROE, Gearing, etc.\", exact=True).click(timeout=5000)\n",
    "        try:\n",
    "            await page.wait_for_load_state(\"networkidle\", timeout=4000)\n",
    "        except:\n",
    "            pass\n",
    "    except:\n",
    "        pass  # si d√©j√† actif\n",
    "\n",
    "    html = await page.content()\n",
    "    dfs = parse_all_tables(html)\n",
    "    if not dfs:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    target = None\n",
    "    for df in dfs:\n",
    "        cols = {norm_text(c) for c in df.columns}\n",
    "        # attention √† l‚Äôapostrophe ‚Üí d√©j√† normalis√© par norm_text\n",
    "        if (\"Exercice\" in cols or \"Ann√©e\" in cols) and (\n",
    "            {\"Gearing\",\"Marge d'exploitation\",\"Taux de profitabilit√©\",\"ROE\"} & cols\n",
    "        ):\n",
    "            target = df.copy()\n",
    "            break\n",
    "    if target is None:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    if \"Ann√©e\" not in target.columns and \"Exercice\" in target.columns:\n",
    "        target = target.rename(columns={\"Exercice\": \"Ann√©e\"})\n",
    "\n",
    "    keep = [c for c in [\"Ann√©e\",\"Gearing\",\"Marge d'exploitation\",\"Taux de profitabilit√©\",\"ROE\"] if c in target.columns]\n",
    "    target = target[keep]\n",
    "    for c in [k for k in keep if k != \"Ann√©e\"]:\n",
    "        target[c] = target[c].map(clean_num)\n",
    "    target[\"Ticker\"] = ticker\n",
    "    return target\n",
    "\n",
    "async def main():\n",
    "    out = []\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=False, args=[\"--disable-blink-features=AutomationControlled\"])\n",
    "        context = await browser.new_context(storage_state=\"cookies.json\", user_agent=UA, locale=\"fr-FR\")\n",
    "        page = await context.new_page()\n",
    "\n",
    "        for t in TICKERS:\n",
    "            try:\n",
    "                print(f\"üìä {t} ...\")\n",
    "                df_valo = await scrape_valorisation_histo(page, t)\n",
    "                df_perf = await scrape_performances(page, t)\n",
    "\n",
    "                if df_valo.empty and df_perf.empty:\n",
    "                    out.append(pd.DataFrame([{\n",
    "                        \"Ticker\": t, \"Ann√©e\": \"\", \"PER Action\": \"\", \"PER Secteur\": \"\",\n",
    "                        \"PBR Action\": \"\", \"PBR Secteur\": \"\", \"Gearing\": \"\",\n",
    "                        \"Marge d'exploitation\": \"\", \"Taux de profitabilit√©\": \"\", \"ROE\": \"\",\n",
    "                        \"Statut\": \"Aucune donn√©e\"\n",
    "                    }]))\n",
    "                else:\n",
    "                    if df_valo.empty:\n",
    "                        merged = df_perf.copy()\n",
    "                    elif df_perf.empty:\n",
    "                        merged = df_valo.copy()\n",
    "                    else:\n",
    "                        merged = pd.merge(df_valo, df_perf, on=[\"Ticker\",\"Ann√©e\"], how=\"outer\")\n",
    "                    merged[\"Statut\"] = \"\"\n",
    "                    out.append(merged)\n",
    "\n",
    "                time.sleep(0.35)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå {t}: {e}\")\n",
    "                out.append(pd.DataFrame([{\n",
    "                    \"Ticker\": t, \"Ann√©e\": \"\", \"PER Action\": \"\", \"PER Secteur\": \"\",\n",
    "                    \"PBR Action\": \"\", \"PBR Secteur\": \"\", \"Gearing\": \"\",\n",
    "                    \"Marge d'exploitation\": \"\", \"Taux de profitabilit√©\": \"\", \"ROE\": \"\",\n",
    "                    \"Statut\": f\"Erreur: {e}\"\n",
    "                }]))\n",
    "\n",
    "        await browser.close()\n",
    "\n",
    "    final_df = pd.concat(out, ignore_index=True) if out else pd.DataFrame()\n",
    "    cols = [\"Ticker\",\"Ann√©e\",\"PER Action\",\"PER Secteur\",\"PBR Action\",\"PBR Secteur\",\n",
    "            \"Gearing\",\"Marge d'exploitation\",\"Taux de profitabilit√©\",\"ROE\",\"Statut\"]\n",
    "    for c in cols:\n",
    "        if c not in final_df.columns:\n",
    "            final_df[c] = \"\"\n",
    "    final_df = final_df[cols]\n",
    "    final_df.to_csv(\"valorisation_performances.csv\", index=False)\n",
    "    print(\"‚úÖ Fichier g√©n√©r√© : valorisation_performances.csv\")\n",
    "\n",
    "# Ex√©cuter dans Jupyter\n",
    "await main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
