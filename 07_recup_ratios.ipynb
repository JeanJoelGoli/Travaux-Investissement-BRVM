{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6a0e3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé ABJC\n",
      "üîé BICB\n",
      "üîé BICC\n",
      "üîé BNBC\n",
      "üîé BOAB\n",
      "üîé BOABF\n",
      "üîé BOAC\n",
      "üîé BOAM\n",
      "üîé BOAN\n",
      "üîé BOAS\n",
      "üîé CABC\n",
      "üîé CBIBF\n",
      "üîé CFAC\n",
      "üîé CIEC\n",
      "üîé ECOC\n",
      "üîé ETIT\n",
      "üîé FTSC\n",
      "üîé LNBB\n",
      "üîé NEIC\n",
      "üîé NSBC\n",
      "üîé NTLC\n",
      "üîé ONTBF\n",
      "üîé ORAC\n",
      "üîé ORGT\n",
      "üîé PALC\n",
      "üîé PRSC\n",
      "üîé SAFC\n",
      "üîé SCRC\n",
      "üîé SDCC\n",
      "üîé SDSC\n",
      "üîé SEMC\n",
      "üîé SGBC\n",
      "üîé SHEC\n",
      "üîé SIBC\n",
      "üîé SICC\n",
      "üîé SIVC\n",
      "üîé SLBC\n",
      "üîé SMBC\n",
      "üîé SNTS\n",
      "üîé SOGC\n",
      "üîé SPHC\n",
      "üîé STAC\n",
      "üîé STBC\n",
      "üîé SVOC\n",
      "üîé TTLC\n",
      "üîé TTLS\n",
      "üîé UNLC\n",
      "üîé UNXC\n",
      "‚úÖ Fichier g√©n√©r√© : ratios.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from playwright.async_api import async_playwright\n",
    "\n",
    "# --- Liste officielle fournie ---\n",
    "TICKERS = [\n",
    "    \"ABJC\",\"BICB\",\"BICC\",\"BNBC\",\"BOAB\",\"BOABF\",\"BOAC\",\"BOAM\",\"BOAN\",\"BOAS\",\n",
    "    \"CABC\",\"CBIBF\",\"CFAC\",\"CIEC\",\"ECOC\",\"ETIT\",\"FTSC\",\"LNBB\",\"NEIC\",\"NSBC\",\n",
    "    \"NTLC\",\"ONTBF\",\"ORAC\",\"ORGT\",\"PALC\",\"PRSC\",\"SAFC\",\"SCRC\",\"SDCC\",\"SDSC\",\n",
    "    \"SEMC\",\"SGBC\",\"SHEC\",\"SIBC\",\"SICC\",\"SIVC\",\"SLBC\",\"SMBC\",\"SNTS\",\"SOGC\",\n",
    "    \"SPHC\",\"STAC\",\"STBC\",\"SVOC\",\"TTLC\",\"TTLS\",\"UNLC\",\"UNXC\"\n",
    "]\n",
    "\n",
    "BASE_URL = \"https://www.richbourse.com/investisseur/analyse-societe/ratios/{ticker}\"\n",
    "\n",
    "# Colonnes attendues (cr√©√©es si absentes)\n",
    "TARGET_COLS = [\n",
    "    \"Ticker\",\n",
    "    \"Secteur d'activit√©\",\n",
    "    \"Symbole\",\n",
    "    \"Quantit√© totale de titres\",\n",
    "    \"Quantit√© de titres du flottant\",\n",
    "    \"Capital social\",\n",
    "    \"Cours de l'action\",\n",
    "    \"Capitalisation boursi√®re\",\n",
    "    \"Volume moyen\",\n",
    "    \"Book value (BV)\",\n",
    "    \"Book value per share (BVPS)\",\n",
    "    \"Price Earning Ratio (PER)\",\n",
    "    \"PER relatif sectoriel\",\n",
    "    \"Price-to-Book Ratio (PBR)\",\n",
    "    \"Levrage\",\n",
    "    \"Gearing\",\n",
    "    \"PBR relatif sectoriel\",\n",
    "    \"Price-to-Sales (PSR)\",\n",
    "    \"Return on equity (ROE)\",\n",
    "    \"Return on Asset (ROA)\",\n",
    "    \"B√©n√©fice net par action (BNPA)\",\n",
    "    \"Statut\"\n",
    "]\n",
    "\n",
    "# Nettoyages\n",
    "def clean_number(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = s.strip()\n",
    "    # couper le texte annexe √©ventuel apr√®s \" (\"\n",
    "    s = re.split(r\"\\(\", s)[0]\n",
    "    # enlever % et convertir virgule d√©cimale\n",
    "    s = s.replace(\"%\", \"\").replace(\",\", \".\")\n",
    "    # supprimer espaces (y compris ins√©cables)\n",
    "    s = s.replace(\"\\xa0\", \" \").replace(\" \", \"\")\n",
    "    return s\n",
    "\n",
    "def normalize_key(k: str) -> str:\n",
    "    k = k.strip()\n",
    "    # uniformiser quelques variantes d‚Äô√©criture √©ventuelles\n",
    "    aliases = {\n",
    "        \"Secteur d‚Äôactivit√©\": \"Secteur d'activit√©\",\n",
    "        \"Lev rage\": \"Levrage\",\n",
    "        \"Leverage\": \"Levrage\",\n",
    "        \"Book value\": \"Book value (BV)\",\n",
    "        \"Book value (BVPS)\": \"Book value per share (BVPS)\",\n",
    "        \"BVPS\": \"Book value per share (BVPS)\",\n",
    "        \"PER\": \"Price Earning Ratio (PER)\",\n",
    "        \"P/E\": \"Price Earning Ratio (PER)\",\n",
    "        \"PBR\": \"Price-to-Book Ratio (PBR)\",\n",
    "        \"ROE\": \"Return on equity (ROE)\",\n",
    "        \"ROA\": \"Return on Asset (ROA)\",\n",
    "        \"BNPA\": \"B√©n√©fice net par action (BNPA)\",\n",
    "    }\n",
    "    return aliases.get(k, k)\n",
    "\n",
    "async def scrape_ratios_for_ticker(page, ticker: str) -> dict:\n",
    "    url = BASE_URL.format(ticker=ticker)\n",
    "    await page.goto(url, timeout=60000)\n",
    "    # l'onglet ‚ÄúBilan‚Äù est la vue par d√©faut : attendre le bloc\n",
    "    # on tol√®re les pages sans tableau en capturant tout le contenu\n",
    "    await page.wait_for_load_state(\"domcontentloaded\", timeout=15000)\n",
    "    try:\n",
    "        await page.wait_for_selector(\"div.tab-content, .panel, body\", timeout=8000)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    html = await page.content()\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    data = {c: \"\" for c in TARGET_COLS}\n",
    "    data[\"Ticker\"] = ticker\n",
    "    data[\"Statut\"] = \"\"\n",
    "\n",
    "    # R√©cup√©rer toutes les listes/paragraphes contenant des paires \"Libell√© : Valeur\"\n",
    "    # On parcourt tous les <li> et <p>\n",
    "    candidates = []\n",
    "    candidates.extend(soup.find_all(\"li\"))\n",
    "    candidates.extend(soup.find_all(\"p\"))\n",
    "\n",
    "    for node in candidates:\n",
    "        txt = node.get_text(\" \", strip=True)\n",
    "        if \":\" not in txt:\n",
    "            continue\n",
    "        # scinder √† la premi√®re occurrence de ':'\n",
    "        left, right = txt.split(\":\", 1)\n",
    "        key = normalize_key(left)\n",
    "        val = right.strip()\n",
    "        if key in TARGET_COLS:\n",
    "            data[key] = clean_number(val)\n",
    "\n",
    "    # Si rien d‚Äôutile n‚Äôa √©t√© rempli en dehors du Ticker\n",
    "    useful = [k for k in TARGET_COLS if k not in (\"Ticker\",\"Statut\")]\n",
    "    if all((data.get(k, \"\") == \"\" for k in useful)):\n",
    "        data[\"Statut\"] = \"Aucune donn√©e\"\n",
    "\n",
    "    return data\n",
    "\n",
    "async def run_all():\n",
    "    out_rows = []\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=False)  # True pour invisible\n",
    "        context = await browser.new_context(storage_state=\"cookies.json\")  # session premium\n",
    "        page = await context.new_page()\n",
    "\n",
    "        for t in TICKERS:\n",
    "            try:\n",
    "                print(f\"üîé {t}\")\n",
    "                row = await scrape_ratios_for_ticker(page, t)\n",
    "                out_rows.append(row)\n",
    "                time.sleep(0.5)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå {t}: {e}\")\n",
    "                out_rows.append({\"Ticker\": t, \"Statut\": f\"Erreur: {e}\"})\n",
    "\n",
    "        await browser.close()\n",
    "\n",
    "    df = pd.DataFrame(out_rows)\n",
    "    # s‚Äôassurer que toutes les colonnes cibles existent et ordre correct\n",
    "    for c in TARGET_COLS:\n",
    "        if c not in df.columns:\n",
    "            df[c] = \"\"\n",
    "    df = df[TARGET_COLS]\n",
    "    df.to_csv(\"ratios.csv\", index=False)\n",
    "    print(\"‚úÖ Fichier g√©n√©r√© : ratios.csv\")\n",
    "\n",
    "# Lancer (Notebook/Jupyter) :\n",
    "await run_all()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
