{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d15a7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Écrit: nb_actions_actuel.csv (48 tickers)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0n/svq7n_mn2lg1fv5jbk66hzg00000gn/T/ipykernel_2659/4273191202.py:105: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/var/folders/0n/svq7n_mn2lg1fv5jbk66hzg00000gn/T/ipykernel_2659/4273191202.py:161: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ratio_daily = ratio_daily.groupby(\"Ticker\", group_keys=False).apply(normalize_ratio)\n",
      "/var/folders/0n/svq7n_mn2lg1fv5jbk66hzg00000gn/T/ipykernel_2659/4273191202.py:232: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ratio_snapped = ratio_daily.groupby(\"Ticker\", group_keys=False).apply(segment_and_snap)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Écrit: recon_nb_actions_journalier.csv\n",
      "✅ Écrit: recap_changements_capitaux.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0n/svq7n_mn2lg1fv5jbk66hzg00000gn/T/ipykernel_2659/4273191202.py:370: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  tmp_merge[\"Date\"] = pd.to_datetime(tmp_merge[\"Date\"], errors=\"coerce\")\n",
      "/var/folders/0n/svq7n_mn2lg1fv5jbk66hzg00000gn/T/ipykernel_2659/4273191202.py:396: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  enriched[date_orig] = pd.to_datetime(enriched[date_orig], errors=\"coerce\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Écrit: combined_journalier_capi.csv (tri par ticker, dates décroissantes)\n",
      "\n",
      "Aperçu événements (top 10):\n",
      "   Ticker Date_Changement  Ratio_Event   k_pq       cap_pre      cap_post  \\\n",
      "0    ABJC      2016-09-30     0.050000   1:20  9.084240e+10  7.174640e+10   \n",
      "1    BICC      2017-10-09     0.100000   1:10  1.386750e+11  1.482500e+11   \n",
      "2    BNBC      2017-07-27     0.050000   1:20  3.444480e+10  3.841920e+10   \n",
      "3    BOAB      2017-06-20     0.500000    1:2  2.175035e+11  2.088894e+11   \n",
      "4    BOAB      2017-10-31     0.100000   1:10  1.419636e+11  1.470338e+11   \n",
      "5    BOAB      2024-09-03     0.500000    1:2  1.521039e+11  1.829303e+11   \n",
      "6   BOABF      2017-06-27     0.500000    1:2  2.200000e+11  2.197800e+11   \n",
      "7   BOABF      2017-10-24     0.100000   1:10  1.645380e+11  1.672000e+11   \n",
      "8   BOABF      2024-08-28     0.500000    1:2  1.502600e+11  1.760000e+11   \n",
      "9    BOAC      2017-06-21     0.500000    1:2  1.720000e+11  1.769600e+11   \n",
      "10   BOAC      2017-10-26     0.100000   1:10  8.098000e+10  7.450000e+10   \n",
      "11   BOAC      2024-10-25     0.500000    1:2  2.079000e+11  2.320000e+11   \n",
      "12   BOAM      2017-09-20     0.666667    2:3  8.540000e+10  9.150000e+10   \n",
      "13   BOAM      2017-12-22     0.200000    1:5  8.454600e+10  9.516000e+10   \n",
      "14   BOAM      2024-08-28     0.666667    2:3  3.696600e+10  4.529250e+10   \n",
      "15   BOAN      2017-06-21     0.769231  10:13  8.000000e+10  8.448700e+10   \n",
      "16   BOAN      2017-10-27     0.100000   1:10  5.134350e+10  4.940000e+10   \n",
      "17   BOAN      2024-09-04     0.625000    5:8  6.786000e+10  7.904000e+10   \n",
      "18   BOAS      2017-06-27     0.500000    1:2  8.874000e+10  8.402400e+10   \n",
      "19   BOAS      2017-10-30     0.100000   1:10  7.440000e+10  6.600000e+10   \n",
      "20   BOAS      2024-08-29     0.666667    2:3  1.125600e+11  1.303200e+11   \n",
      "21   CABC      2017-08-17     0.025000   1:20  5.846000e+09  5.860800e+09   \n",
      "22  CBIBF      2017-09-21     0.977011    1:1  2.618391e+11  2.752000e+11   \n",
      "23  CBIBF      2017-12-14     0.200000    1:5  2.878400e+11  2.976000e+11   \n",
      "24   CFAC      2017-12-19     0.010000         6.801446e+10  7.526934e+10   \n",
      "25   CIEC      2017-10-19     0.050000   1:20  1.512000e+11  1.674400e+11   \n",
      "26   ECOC      2018-12-27     0.200000    1:5  2.241660e+11  2.323135e+11   \n",
      "27   ETIT      2008-06-09     0.200000    1:5  3.074298e+12  2.983878e+12   \n",
      "28   FTSC      2018-01-31     0.250000    1:4  5.817793e+10  6.135127e+10   \n",
      "29   NEIC      2017-08-10     0.040000   1:20  5.616963e+08  5.999938e+08   \n",
      "30   NTLC      2017-09-11     0.050000   1:20  5.307931e+10  6.168677e+10   \n",
      "31  ONTBF      2013-11-29     0.100000   1:10  2.142000e+11  2.140300e+11   \n",
      "32  ONTBF      2018-08-29     0.500000    1:2  2.703000e+11  2.720000e+11   \n",
      "33   PALC      2017-11-06     0.500000    1:2  6.956692e+10  6.454264e+10   \n",
      "34   PRSC      2019-10-28     0.015625         1.920000e+10  2.073600e+10   \n",
      "35   SAFC      2017-10-17     0.400000    2:5  2.923110e+09  3.631152e+09   \n",
      "36   SAFC      2019-01-08     0.040000   1:20  1.721387e+09  1.745746e+09   \n",
      "37   SCRC      2017-12-05     0.250000    1:4  1.543500e+10  1.568000e+10   \n",
      "38   SDCC      2017-12-28     0.100000   1:10  4.679550e+10  5.319000e+10   \n",
      "39   SDSC      2017-07-31     0.020000         2.046767e+11  2.122977e+11   \n",
      "40   SEMC      2018-12-28     0.025000   1:20  7.282943e+09  7.556880e+09   \n",
      "41   SGBC      2017-08-25     0.100000   1:10  3.733333e+11  3.733333e+11   \n",
      "42   SHEC      2016-11-04     0.020000         1.650537e+11  1.827000e+11   \n",
      "43   SIBC      2018-06-15     0.200000    1:5  1.675000e+11  1.800000e+11   \n",
      "44   SIBC      2024-11-14     0.500000    1:2  3.647500e+11  3.690000e+11   \n",
      "45   SIVC      2017-12-22     0.100000   1:10  3.755620e+09  3.668280e+09   \n",
      "46   SLBC      2014-12-30     0.500000    1:2  3.292168e+11  3.292168e+11   \n",
      "47   SLBC      2024-09-30     0.100000   1:10  1.563780e+11  1.976124e+11   \n",
      "48   SMBC      2019-02-25     0.250000    1:4  3.732926e+10  3.780672e+10   \n",
      "49   SNTS      2012-11-23     0.100000   1:10  1.400000e+12  1.400000e+12   \n",
      "\n",
      "    cap_change_pct            Decision  Confidence  \\\n",
      "0        -0.210210  Split/Regroupement        0.70   \n",
      "1         0.069046  Split/Regroupement        0.90   \n",
      "2         0.115385  Split/Regroupement        0.70   \n",
      "3        -0.039605  Split/Regroupement        0.90   \n",
      "4         0.035714  Split/Regroupement        0.90   \n",
      "5         0.202667  Split/Regroupement        0.70   \n",
      "6        -0.001000  Split/Regroupement        0.90   \n",
      "7         0.016179  Split/Regroupement        0.90   \n",
      "8         0.171303  Split/Regroupement        0.70   \n",
      "9         0.028837  Split/Regroupement        0.90   \n",
      "10       -0.080020  Split/Regroupement        0.70   \n",
      "11        0.115921  Split/Regroupement        0.70   \n",
      "12        0.071429  Split/Regroupement        0.90   \n",
      "13        0.125541  Split/Regroupement        0.70   \n",
      "14        0.225248  Split/Regroupement        0.70   \n",
      "15        0.056087  Split/Regroupement        0.90   \n",
      "16       -0.037853  Split/Regroupement        0.90   \n",
      "17        0.164751  Split/Regroupement        0.70   \n",
      "18       -0.053144  Split/Regroupement        0.90   \n",
      "19       -0.112903  Split/Regroupement        0.70   \n",
      "20        0.157783  Split/Regroupement        0.70   \n",
      "21        0.002532  Augmentation/Autre        0.70   \n",
      "22        0.051027  Augmentation/Autre        0.70   \n",
      "23        0.033908  Split/Regroupement        0.90   \n",
      "24        0.106667  Augmentation/Autre        0.85   \n",
      "25        0.107407  Split/Regroupement        0.70   \n",
      "26        0.036346  Split/Regroupement        0.90   \n",
      "27       -0.029412  Split/Regroupement        0.90   \n",
      "28        0.054545  Split/Regroupement        0.90   \n",
      "29        0.068182  Augmentation/Autre        0.70   \n",
      "30        0.162162  Split/Regroupement        0.70   \n",
      "31       -0.000794  Split/Regroupement        0.90   \n",
      "32        0.006289  Split/Regroupement        0.90   \n",
      "33       -0.072222  Split/Regroupement        0.90   \n",
      "34        0.080000  Augmentation/Autre        0.85   \n",
      "35        0.242222  Split/Regroupement        0.70   \n",
      "36        0.014151  Augmentation/Autre        0.70   \n",
      "37        0.015873  Split/Regroupement        0.90   \n",
      "38        0.136648  Split/Regroupement        0.70   \n",
      "39        0.037234  Augmentation/Autre        0.70   \n",
      "40        0.037613  Augmentation/Autre        0.70   \n",
      "41        0.000000  Split/Regroupement        0.90   \n",
      "42        0.106912  Augmentation/Autre        0.85   \n",
      "43        0.074627  Split/Regroupement        0.90   \n",
      "44        0.011652  Split/Regroupement        0.90   \n",
      "45       -0.023256  Split/Regroupement        0.90   \n",
      "46        0.000000  Split/Regroupement        0.90   \n",
      "47        0.263684  Split/Regroupement        0.70   \n",
      "48        0.012790  Split/Regroupement        0.90   \n",
      "49        0.000000  Split/Regroupement        0.90   \n",
      "\n",
      "                                               Reason  \n",
      "0         Ratio simple p:q mais variation cap ambiguë  \n",
      "1       Ratio simple p:q et capitalisation ~inchangée  \n",
      "2         Ratio simple p:q mais variation cap ambiguë  \n",
      "3       Ratio simple p:q et capitalisation ~inchangée  \n",
      "4       Ratio simple p:q et capitalisation ~inchangée  \n",
      "5         Ratio simple p:q mais variation cap ambiguë  \n",
      "6       Ratio simple p:q et capitalisation ~inchangée  \n",
      "7       Ratio simple p:q et capitalisation ~inchangée  \n",
      "8         Ratio simple p:q mais variation cap ambiguë  \n",
      "9       Ratio simple p:q et capitalisation ~inchangée  \n",
      "10        Ratio simple p:q mais variation cap ambiguë  \n",
      "11        Ratio simple p:q mais variation cap ambiguë  \n",
      "12      Ratio simple p:q et capitalisation ~inchangée  \n",
      "13        Ratio simple p:q mais variation cap ambiguë  \n",
      "14        Ratio simple p:q mais variation cap ambiguë  \n",
      "15      Ratio simple p:q et capitalisation ~inchangée  \n",
      "16      Ratio simple p:q et capitalisation ~inchangée  \n",
      "17        Ratio simple p:q mais variation cap ambiguë  \n",
      "18      Ratio simple p:q et capitalisation ~inchangée  \n",
      "19        Ratio simple p:q mais variation cap ambiguë  \n",
      "20        Ratio simple p:q mais variation cap ambiguë  \n",
      "21        Ratio non simple mais variation cap ambiguë  \n",
      "22        Ratio non simple mais variation cap ambiguë  \n",
      "23      Ratio simple p:q et capitalisation ~inchangée  \n",
      "24  Ratio non simple et capitalisation change sign...  \n",
      "25        Ratio simple p:q mais variation cap ambiguë  \n",
      "26      Ratio simple p:q et capitalisation ~inchangée  \n",
      "27      Ratio simple p:q et capitalisation ~inchangée  \n",
      "28      Ratio simple p:q et capitalisation ~inchangée  \n",
      "29        Ratio non simple mais variation cap ambiguë  \n",
      "30        Ratio simple p:q mais variation cap ambiguë  \n",
      "31      Ratio simple p:q et capitalisation ~inchangée  \n",
      "32      Ratio simple p:q et capitalisation ~inchangée  \n",
      "33      Ratio simple p:q et capitalisation ~inchangée  \n",
      "34  Ratio non simple et capitalisation change sign...  \n",
      "35        Ratio simple p:q mais variation cap ambiguë  \n",
      "36        Ratio non simple mais variation cap ambiguë  \n",
      "37      Ratio simple p:q et capitalisation ~inchangée  \n",
      "38        Ratio simple p:q mais variation cap ambiguë  \n",
      "39        Ratio non simple mais variation cap ambiguë  \n",
      "40        Ratio non simple mais variation cap ambiguë  \n",
      "41      Ratio simple p:q et capitalisation ~inchangée  \n",
      "42  Ratio non simple et capitalisation change sign...  \n",
      "43      Ratio simple p:q et capitalisation ~inchangée  \n",
      "44      Ratio simple p:q et capitalisation ~inchangée  \n",
      "45      Ratio simple p:q et capitalisation ~inchangée  \n",
      "46      Ratio simple p:q et capitalisation ~inchangée  \n",
      "47        Ratio simple p:q mais variation cap ambiguë  \n",
      "48      Ratio simple p:q et capitalisation ~inchangée  \n",
      "49      Ratio simple p:q et capitalisation ~inchangée  \n",
      "\n",
      "Aperçu historique (top 10):\n",
      "   Ticker       Date  nb_actions_estime  ratio_norm_snapped\n",
      "0    ABJC 2000-03-31             545600                20.0\n",
      "1    ABJC 2000-04-03             545600                20.0\n",
      "2    ABJC 2000-04-05             545600                20.0\n",
      "3    ABJC 2000-04-07             545600                20.0\n",
      "4    ABJC 2000-04-10             545600                20.0\n",
      "5    ABJC 2000-04-12             545600                20.0\n",
      "6    ABJC 2000-04-14             545600                20.0\n",
      "7    ABJC 2000-04-17             545600                20.0\n",
      "8    ABJC 2000-04-19             545600                20.0\n",
      "9    ABJC 2000-04-21             545600                20.0\n",
      "10   ABJC 2000-04-26             545600                20.0\n",
      "11   ABJC 2000-05-03             545600                20.0\n",
      "12   ABJC 2000-05-05             545600                20.0\n",
      "13   ABJC 2000-05-08             545600                20.0\n",
      "14   ABJC 2000-05-10             545600                20.0\n",
      "15   ABJC 2000-05-12             545600                20.0\n",
      "16   ABJC 2000-05-15             545600                20.0\n",
      "17   ABJC 2000-05-17             545600                20.0\n",
      "18   ABJC 2000-05-22             545600                20.0\n",
      "19   ABJC 2000-05-24             545600                20.0\n",
      "20   ABJC 2000-05-26             545600                20.0\n",
      "21   ABJC 2000-05-31             545600                20.0\n",
      "22   ABJC 2000-06-02             545600                20.0\n",
      "23   ABJC 2000-06-07             545600                20.0\n",
      "24   ABJC 2000-06-09             545600                20.0\n",
      "25   ABJC 2000-06-21             545600                20.0\n",
      "26   ABJC 2000-06-30             545600                20.0\n",
      "27   ABJC 2000-07-07             545600                20.0\n",
      "28   ABJC 2000-07-10             545600                20.0\n",
      "29   ABJC 2000-07-12             545600                20.0\n",
      "30   ABJC 2000-07-21             545600                20.0\n",
      "31   ABJC 2000-07-26             545600                20.0\n",
      "32   ABJC 2000-07-28             545600                20.0\n",
      "33   ABJC 2000-08-11             545600                20.0\n",
      "34   ABJC 2000-08-14             545600                20.0\n",
      "35   ABJC 2000-08-16             545600                20.0\n",
      "36   ABJC 2000-08-23             545600                20.0\n",
      "37   ABJC 2000-09-06             545600                20.0\n",
      "38   ABJC 2000-09-08             545600                20.0\n",
      "39   ABJC 2000-09-15             545600                20.0\n",
      "40   ABJC 2000-09-20             545600                20.0\n",
      "41   ABJC 2000-09-22             545600                20.0\n",
      "42   ABJC 2000-09-29             545600                20.0\n",
      "43   ABJC 2000-10-02             545600                20.0\n",
      "44   ABJC 2000-10-04             545600                20.0\n",
      "45   ABJC 2000-10-06             545600                20.0\n",
      "46   ABJC 2000-10-09             545600                20.0\n",
      "47   ABJC 2000-10-11             545600                20.0\n",
      "48   ABJC 2000-10-13             545600                20.0\n",
      "49   ABJC 2000-10-18             545600                20.0\n",
      "\n",
      "Aperçu enriched (top 5):\n",
      "    Ticker        Date  Variation  Volume Devise Total  Cours Ajuste  \\\n",
      "0   ABJC J  2025-09-26       0.56               983325          1810   \n",
      "1   ABJC J  2025-09-25      -0.55              7360215          1800   \n",
      "2   ABJC J  2025-09-24       0.00              1301995          1810   \n",
      "3   ABJC J  2025-09-23       0.56              1800530          1810   \n",
      "4   ABJC J  2025-09-22       0.56              3892425          1800   \n",
      "5   ABJC J  2025-09-19       0.00               884880          1790   \n",
      "6   ABJC J  2025-09-18      -0.56               657930          1790   \n",
      "7   ABJC J  2025-09-17       0.28               867950          1800   \n",
      "8   ABJC J  2025-09-16      -0.83               690720          1795   \n",
      "9   ABJC J  2025-09-15       0.84              1812550          1810   \n",
      "10  ABJC J  2025-09-12       0.00               371440          1795   \n",
      "11  ABJC J  2025-09-11       4.06              1006645          1795   \n",
      "12  ABJC J  2025-09-10      -4.17              3677050          1725   \n",
      "13  ABJC J  2025-09-09       2.86              4295735          1800   \n",
      "14  ABJC J  2025-09-08      -1.69              4052520          1750   \n",
      "15  ABJC J  2025-09-05       1.14              2040605          1780   \n",
      "16  ABJC J  2025-09-03      -1.12              1410625          1760   \n",
      "17  ABJC J  2025-09-02      -1.11               686850          1780   \n",
      "18  ABJC J  2025-09-01       2.86               631470          1800   \n",
      "19  ABJC J  2025-08-29      -3.31               720370          1750   \n",
      "20  ABJC J  2025-08-28       0.56               719325          1810   \n",
      "21  ABJC J  2025-08-27      -1.64               691920          1800   \n",
      "22  ABJC J  2025-08-26      -0.27              1935330          1830   \n",
      "23  ABJC J  2025-08-25       1.94              1469530          1835   \n",
      "24  ABJC J  2025-08-22       0.00              3416285          1800   \n",
      "25  ABJC J  2025-08-21       2.56             13523960          1800   \n",
      "26  ABJC J  2025-08-20       0.29              1727855          1755   \n",
      "27  ABJC J  2025-08-19       2.94               270925          1750   \n",
      "28  ABJC J  2025-08-18      -3.68              7930835          1700   \n",
      "29  ABJC J  2025-08-14       0.86               316500          1765   \n",
      "30  ABJC J  2025-08-13       0.57               952390          1750   \n",
      "31  ABJC J  2025-08-12      -1.42              1136610          1740   \n",
      "32  ABJC J  2025-08-11      -1.40              3752245          1765   \n",
      "33  ABJC J  2025-08-08       4.07              1523510          1790   \n",
      "34  ABJC J  2025-08-06       1.18              4926720          1720   \n",
      "35  ABJC J  2025-08-05      -1.16               396160          1700   \n",
      "36  ABJC J  2025-08-04       1.18              1206040          1720   \n",
      "37  ABJC J  2025-08-01       1.19              5280480          1700   \n",
      "38  ABJC J  2025-07-31      -1.75             26060290          1680   \n",
      "39  ABJC J  2025-07-30       1.79             24673205          1710   \n",
      "40  ABJC J  2025-07-29       1.82              1523635          1680   \n",
      "41  ABJC J  2025-07-28       0.00               283800          1650   \n",
      "42  ABJC J  2025-07-25       2.48               349110          1650   \n",
      "43  ABJC J  2025-07-24       0.00               483000          1610   \n",
      "44  ABJC J  2025-07-23      -2.42              3809850          1610   \n",
      "45  ABJC J  2025-07-22      -2.94              1590920          1650   \n",
      "46  ABJC J  2025-07-21       0.00               843110          1700   \n",
      "47  ABJC J  2025-07-18       0.59              1382400          1700   \n",
      "48  ABJC J  2025-07-17       0.00              1101880          1690   \n",
      "49  ABJC J  2025-07-16       0.00              2660755          1690   \n",
      "\n",
      "    Volume Ajuste Total  Cours Normal  Volume Normal Total  nb_actions_estime  \\\n",
      "0                   546          1810                  546           10912000   \n",
      "1                  4089          1800                 4089           10912000   \n",
      "2                   713          1810                  713           10912000   \n",
      "3                   999          1810                  999           10912000   \n",
      "4                  2170          1800                 2170           10912000   \n",
      "5                   494          1790                  494           10912000   \n",
      "6                   366          1790                  366           10912000   \n",
      "7                   483          1800                  483           10912000   \n",
      "8                   384          1795                  384           10912000   \n",
      "9                  1001          1810                 1001           10912000   \n",
      "10                  212          1795                  212           10912000   \n",
      "11                  574          1795                  574           10912000   \n",
      "12                 2083          1725                 2083           10912000   \n",
      "13                 2452          1800                 2452           10912000   \n",
      "14                 2295          1750                 2295           10912000   \n",
      "15                 1164          1780                 1164           10912000   \n",
      "16                  804          1760                  804           10912000   \n",
      "17                  390          1780                  390           10912000   \n",
      "18                  355          1800                  355           10912000   \n",
      "19                  414          1750                  414           10912000   \n",
      "20                  398          1810                  398           10912000   \n",
      "21                  383          1800                  383           10912000   \n",
      "22                 1070          1830                 1070           10912000   \n",
      "23                  803          1835                  803           10912000   \n",
      "24                 1887          1800                 1887           10912000   \n",
      "25                 7550          1800                 7550           10912000   \n",
      "26                  985          1755                  985           10912000   \n",
      "27                  155          1750                  155           10912000   \n",
      "28                 4514          1700                 4514           10912000   \n",
      "29                  180          1765                  180           10912000   \n",
      "30                  545          1750                  545           10912000   \n",
      "31                  671          1740                  671           10912000   \n",
      "32                 2120          1765                 2120           10912000   \n",
      "33                  849          1790                  849           10912000   \n",
      "34                 2881          1720                 2881           10912000   \n",
      "35                  231          1700                  231           10912000   \n",
      "36                  705          1720                  705           10912000   \n",
      "37                 3290          1700                 3290           10912000   \n",
      "38                15439          1680                15439           10912000   \n",
      "39                15396          1710                15396           10912000   \n",
      "40                  903          1680                  903           10912000   \n",
      "41                  172          1650                  172           10912000   \n",
      "42                  211          1650                  211           10912000   \n",
      "43                  300          1610                  300           10912000   \n",
      "44                 2366          1610                 2366           10912000   \n",
      "45                  941          1650                  941           10912000   \n",
      "46                  498          1700                  498           10912000   \n",
      "47                  847          1700                  847           10912000   \n",
      "48                  652          1690                  652           10912000   \n",
      "49                 1570          1690                 1570           10912000   \n",
      "\n",
      "    Capitalisation  \n",
      "0    19750720000.0  \n",
      "1    19641600000.0  \n",
      "2    19750720000.0  \n",
      "3    19750720000.0  \n",
      "4    19641600000.0  \n",
      "5    19532480000.0  \n",
      "6    19532480000.0  \n",
      "7    19641600000.0  \n",
      "8    19587040000.0  \n",
      "9    19750720000.0  \n",
      "10   19587040000.0  \n",
      "11   19587040000.0  \n",
      "12   18823200000.0  \n",
      "13   19641600000.0  \n",
      "14   19096000000.0  \n",
      "15   19423360000.0  \n",
      "16   19205120000.0  \n",
      "17   19423360000.0  \n",
      "18   19641600000.0  \n",
      "19   19096000000.0  \n",
      "20   19750720000.0  \n",
      "21   19641600000.0  \n",
      "22   19968960000.0  \n",
      "23   20023520000.0  \n",
      "24   19641600000.0  \n",
      "25   19641600000.0  \n",
      "26   19150560000.0  \n",
      "27   19096000000.0  \n",
      "28   18550400000.0  \n",
      "29   19259680000.0  \n",
      "30   19096000000.0  \n",
      "31   18986880000.0  \n",
      "32   19259680000.0  \n",
      "33   19532480000.0  \n",
      "34   18768640000.0  \n",
      "35   18550400000.0  \n",
      "36   18768640000.0  \n",
      "37   18550400000.0  \n",
      "38   18332160000.0  \n",
      "39   18659520000.0  \n",
      "40   18332160000.0  \n",
      "41   18004800000.0  \n",
      "42   18004800000.0  \n",
      "43   17568320000.0  \n",
      "44   17568320000.0  \n",
      "45   18004800000.0  \n",
      "46   18550400000.0  \n",
      "47   18550400000.0  \n",
      "48   18441280000.0  \n",
      "49   18441280000.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fractions import Fraction\n",
    "import re\n",
    "\n",
    "# =======================\n",
    "# FICHIERS\n",
    "# =======================\n",
    "INPUT_PRICES_CSV = \"combined_journalier.csv\"\n",
    "OUTPUT_SHARES_DAILY = \"recon_nb_actions_journalier.csv\"\n",
    "OUTPUT_EVENTS = \"recap_changements_capitaux.csv\"\n",
    "OUTPUT_CURRENT_SHARES = \"nb_actions_actuel.csv\"\n",
    "OUTPUT_ENRICHED = \"combined_journalier_capi.csv\"\n",
    "\n",
    "# =======================\n",
    "# PARAMÈTRES\n",
    "# =======================\n",
    "EPS_RATIO_VALID = 1e-12\n",
    "\n",
    "# Détection et lissage des paliers (anti micro-écarts)\n",
    "EVENT_CHANGE_THRESH = 0.008   # 0.8% pour détecter les \"vrais\" sauts (avant consolidation)\n",
    "MIN_SEG_LEN = 3               # longueur minimale d'un segment (jours) avant fusion\n",
    "MERGE_TOL = 0.004             # 0.4%: si 2 segments voisins ont des médianes trop proches -> fusion\n",
    "Q_TOL = 0.006                 # 0.6%: tolérance pour arrondir un palier à un ratio p/q simple\n",
    "\n",
    "# Typage Split vs Augmentation\n",
    "CAP_TOL = 0.075               # 7.5%: cap ~inchangée vs changement significatif\n",
    "WINDOW = 3                    # jours médiane avant/après pour la cap\n",
    "RATIONAL_TOL = 0.005          # 0.5%\n",
    "MAX_DENOM = 20\n",
    "\n",
    "# =======================\n",
    "# UTILS\n",
    "# =======================\n",
    "def normalize_cols(cols):\n",
    "    return [c.strip().lower() for c in cols]\n",
    "\n",
    "def normalize_ticker(x: str) -> str:\n",
    "    if pd.isna(x):\n",
    "        return x\n",
    "    s = str(x).strip().upper()\n",
    "    s = s.split()[0]                      # garde la 1ère partie avant espace\n",
    "    s = re.split(r\"[^A-Z0-9]+\", s)[0]     # bloc alphanum initial\n",
    "    return s\n",
    "\n",
    "def find_col(df, targets):\n",
    "    for cand in targets:\n",
    "        if cand in df.columns:\n",
    "            return cand\n",
    "    return None\n",
    "\n",
    "def approx_simple_ratio(x, tol=RATIONAL_TOL, max_den=MAX_DENOM):\n",
    "    if not np.isfinite(x) or x <= 0:\n",
    "        return (None, None, None, False)\n",
    "    frac = Fraction(x).limit_denominator(max_den)\n",
    "    x_hat = frac.numerator / frac.denominator\n",
    "    rel_err = abs(x - x_hat) / x\n",
    "    return (frac.numerator, frac.denominator, x_hat, rel_err <= tol)\n",
    "\n",
    "# =======================\n",
    "# TABLE NOMBRE D'ACTIONS ACTUEL\n",
    "# =======================\n",
    "\n",
    "df_current = base = pd.read_csv(\"richbourse_nb_actions_actuel.csv\")\n",
    "df_current[\"Ticker\"] = df_current[\"Ticker\"].apply(normalize_ticker)\n",
    "df_current.to_csv(OUTPUT_CURRENT_SHARES, index=False)\n",
    "print(f\"✅ Écrit: {OUTPUT_CURRENT_SHARES} ({len(df_current)} tickers)\")\n",
    "\n",
    "# =======================\n",
    "# CHARGER TABLE D'ORIGINE\n",
    "# =======================\n",
    "base = pd.read_csv(INPUT_PRICES_CSV)\n",
    "base.columns = normalize_cols(base.columns)\n",
    "\n",
    "col_map_candidates = {\n",
    "    \"ticker\": [\"ticker\",\"symbole\",\"code\"],\n",
    "    \"date\": [\"date\"],\n",
    "    \"cours_ajuste\": [\"cours ajuste\",\"cours ajusté\",\"close ajusté\",\"px ajusté\",\"prix ajusté\",\"cours ajustee\",\"cours_ajuste\",\"cours_ajusté\"],\n",
    "    \"cours_normal\": [\"cours normal\",\"close\",\"px normal\",\"prix normal\",\"cours_normal\",\"prix\"],\n",
    "    \"vol_adj\": [\"volume ajuste total\",\"volume ajusté total\",\"vol ajusté\",\"volume ajusté\",\"vol_ajuste\",\"vol_ajusté\",\"volume ajuste\",\"volume ajustee\"],\n",
    "    \"vol_norm\": [\"volume normal total\",\"vol normal total\",\"volume\",\"volume normal\",\"vol normal\",\"vol_normal\"],\n",
    "}\n",
    "\n",
    "col_ticker = find_col(base, col_map_candidates[\"ticker\"])\n",
    "col_date   = find_col(base, col_map_candidates[\"date\"])\n",
    "col_ca     = find_col(base, col_map_candidates[\"cours_ajuste\"])\n",
    "col_cn     = find_col(base, col_map_candidates[\"cours_normal\"])\n",
    "col_va     = find_col(base, col_map_candidates[\"vol_adj\"])\n",
    "col_vn     = find_col(base, col_map_candidates[\"vol_norm\"])\n",
    "\n",
    "required = [col_ticker, col_date, (col_ca or col_va), (col_cn or col_vn)]\n",
    "if any(c is None for c in required):\n",
    "    raise ValueError(\"Colonnes manquantes dans combined_journalier.csv (il faut au moins Ticker, Date, et l'un des couples prix/vol. ajusté/normal).\")\n",
    "\n",
    "df = base[[c for c in [col_ticker,col_date,col_ca,col_cn,col_va,col_vn] if c is not None]].copy()\n",
    "rename_map = {}\n",
    "if col_ticker: rename_map[col_ticker] = \"Ticker\"\n",
    "if col_date:   rename_map[col_date]   = \"Date\"\n",
    "if col_ca:     rename_map[col_ca]     = \"Cours_Ajuste\"\n",
    "if col_cn:     rename_map[col_cn]     = \"Cours_Normal\"\n",
    "if col_va:     rename_map[col_va]     = \"Vol_Ajuste\"\n",
    "if col_vn:     rename_map[col_vn]     = \"Vol_Normal\"\n",
    "df = df.rename(columns=rename_map)\n",
    "\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"Date\",\"Ticker\"])\n",
    "df[\"Ticker\"] = df[\"Ticker\"].apply(normalize_ticker)\n",
    "df = df.sort_values([\"Ticker\",\"Date\"])\n",
    "\n",
    "for c in [\"Cours_Ajuste\",\"Cours_Normal\",\"Vol_Ajuste\",\"Vol_Normal\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# =======================\n",
    "# RATIO JOUR: PRIX PRIORITAIRE, VOLUME EN SECOURS\n",
    "# =======================\n",
    "def compute_ratio_row(row):\n",
    "    ca = row.get(\"Cours_Ajuste\", np.nan)\n",
    "    cn = row.get(\"Cours_Normal\", np.nan)\n",
    "    va = row.get(\"Vol_Ajuste\", np.nan)\n",
    "    vn = row.get(\"Vol_Normal\", np.nan)\n",
    "\n",
    "    r_price = np.nan\n",
    "    r_vol = np.nan\n",
    "    if pd.notna(ca) and pd.notna(cn) and abs(ca) > EPS_RATIO_VALID:\n",
    "        r_price = cn / ca\n",
    "    if pd.notna(va) and pd.notna(vn) and abs(va) > EPS_RATIO_VALID:\n",
    "        r_vol = vn / va\n",
    "\n",
    "    if pd.notna(r_price) and np.isfinite(r_price) and r_price > 0:\n",
    "        return r_price\n",
    "    if pd.notna(r_vol) and np.isfinite(r_vol) and r_vol > 0:\n",
    "        return r_vol\n",
    "    return np.nan\n",
    "\n",
    "df[\"ratio_raw\"] = df.apply(compute_ratio_row, axis=1)\n",
    "\n",
    "# Agrégation par jour (médiane robuste si multi-lignes)\n",
    "ratio_daily = (\n",
    "    df.groupby([\"Ticker\",\"Date\"], as_index=False)[\"ratio_raw\"]\n",
    "      .median()\n",
    "      .rename(columns={\"ratio_raw\":\"ratio\"})\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# NORMALISATION SUR LE DERNIER JOUR\n",
    "# =======================\n",
    "def normalize_ratio(group):\n",
    "    group = group.sort_values(\"Date\")\n",
    "    if group[\"ratio\"].notna().any():\n",
    "        last_ratio = group[\"ratio\"].dropna().iloc[-1]\n",
    "        if last_ratio and np.isfinite(last_ratio) and last_ratio > 0:\n",
    "            group[\"ratio_norm\"] = group[\"ratio\"] / last_ratio\n",
    "        else:\n",
    "            group[\"ratio_norm\"] = np.nan\n",
    "    else:\n",
    "        group[\"ratio_norm\"] = np.nan\n",
    "    group[\"ratio_norm\"] = group[\"ratio_norm\"].ffill().bfill()\n",
    "    return group\n",
    "\n",
    "ratio_daily = ratio_daily.groupby(\"Ticker\", group_keys=False).apply(normalize_ratio)\n",
    "\n",
    "# =======================\n",
    "# SEGMENTATION + SNAPPING DES PALIERS (anti micro-écarts)\n",
    "# =======================\n",
    "def segment_and_snap(group):\n",
    "    g = group.sort_values(\"Date\").reset_index(drop=True).copy()\n",
    "    r = g[\"ratio_norm\"].values.astype(float)\n",
    "\n",
    "    if np.all(pd.isna(r)):\n",
    "        g[\"ratio_norm_snapped\"] = np.nan\n",
    "        return g\n",
    "\n",
    "    # indices de rupture initiale\n",
    "    change = [0]\n",
    "    for i in range(1, len(r)):\n",
    "        prev, cur = r[i-1], r[i]\n",
    "        if pd.isna(prev) or pd.isna(cur) or prev <= 0:\n",
    "            continue\n",
    "        if abs(cur/prev - 1.0) > EVENT_CHANGE_THRESH:\n",
    "            change.append(i)\n",
    "    if change[-1] != len(r):\n",
    "        change.append(len(r))\n",
    "\n",
    "    # construire segments [start, end)\n",
    "    segments = []\n",
    "    for s, e in zip(change[:-1], change[1:]):\n",
    "        segments.append((s, e))\n",
    "\n",
    "    # fusionner segments trop courts ou niveaux trop proches\n",
    "    merged = []\n",
    "    i = 0\n",
    "    while i < len(segments):\n",
    "        s, e = segments[i]\n",
    "        # niveau médian du segment\n",
    "        level = np.nanmedian(r[s:e])\n",
    "        # essayer de fusionner avec le suivant si conditions\n",
    "        j = i + 1\n",
    "        while j < len(segments):\n",
    "            s2, e2 = segments[j]\n",
    "            level2 = np.nanmedian(r[s2:e2])\n",
    "            rel_diff = abs(level2 - level) / max(abs(level), EPS_RATIO_VALID)\n",
    "            seg_len = e - s\n",
    "            seg2_len = e2 - s2\n",
    "            if (rel_diff <= MERGE_TOL) or (seg2_len < MIN_SEG_LEN) or (seg_len < MIN_SEG_LEN):\n",
    "                # fusion\n",
    "                e = e2\n",
    "                level = np.nanmedian(r[s:e])\n",
    "                j += 1\n",
    "            else:\n",
    "                break\n",
    "        merged.append((s, e))\n",
    "        i = j\n",
    "\n",
    "    # calcul niveaux \"snappés\" paliers propres\n",
    "    snapped_levels = []\n",
    "    for s, e in merged:\n",
    "        level = float(np.nanmedian(r[s:e]))\n",
    "        # si le niveau est proche d'un ratio p/q simple, on le \"snap\" dessus\n",
    "        p,q,xhat,is_simple = approx_simple_ratio(level, tol=Q_TOL, max_den=MAX_DENOM)\n",
    "        snapped = xhat if is_simple else level\n",
    "        snapped_levels.append((s, e, snapped))\n",
    "\n",
    "    # assigner\n",
    "    r_snap = np.copy(r)\n",
    "    for s, e, lev in snapped_levels:\n",
    "        r_snap[s:e] = lev\n",
    "\n",
    "    g[\"ratio_norm_snapped\"] = r_snap\n",
    "    return g\n",
    "\n",
    "ratio_snapped = ratio_daily.groupby(\"Ticker\", group_keys=False).apply(segment_and_snap)\n",
    "\n",
    "# =======================\n",
    "# RECONSTITUTION NB D'ACTIONS (sur paliers snappés)\n",
    "# =======================\n",
    "df_all = ratio_snapped.merge(df_current, on=\"Ticker\", how=\"left\")\n",
    "\n",
    "def compute_shares(row):\n",
    "    r = row[\"ratio_norm_snapped\"]\n",
    "    n = row[\"nb_actions_actuel\"]\n",
    "    if pd.notna(n) and pd.notna(r) and r > 0:\n",
    "        return n / r\n",
    "    return np.nan\n",
    "\n",
    "df_all[\"nb_actions_estime\"] = df_all.apply(compute_shares, axis=1)\n",
    "df_all[\"nb_actions_estime\"] = df_all[\"nb_actions_estime\"].round().astype(\"Int64\")\n",
    "\n",
    "# =======================\n",
    "# PRIX NORMAL EFFECTIF & MARKET CAP (pour typage événements)\n",
    "# =======================\n",
    "# Prix/ratio \"bruts\" par jour (pour proxy CN si manquant)\n",
    "pr_daily = (\n",
    "    df.groupby([\"Ticker\",\"Date\"], as_index=False)[[\"Cours_Ajuste\",\"Cours_Normal\",\"Vol_Ajuste\",\"Vol_Normal\"]]\n",
    "      .median()\n",
    "      .merge(ratio_daily[[\"Ticker\",\"Date\",\"ratio\"]], on=[\"Ticker\",\"Date\"], how=\"left\")\n",
    ")\n",
    "\n",
    "def prix_normal_effectif_row(row):\n",
    "    cn = row.get(\"Cours_Normal\", np.nan)\n",
    "    ca = row.get(\"Cours_Ajuste\", np.nan)\n",
    "    r  = row.get(\"ratio\", np.nan)\n",
    "    if pd.notna(cn) and np.isfinite(cn) and cn > 0:\n",
    "        return cn\n",
    "    if pd.notna(ca) and np.isfinite(ca) and ca > 0 and pd.notna(r) and np.isfinite(r) and r > 0:\n",
    "        return ca * r\n",
    "    return np.nan\n",
    "\n",
    "cap_base = df_all.merge(pr_daily, on=[\"Ticker\",\"Date\"], how=\"left\")\n",
    "cap_base[\"Prix_Normal_Effectif\"] = cap_base.apply(prix_normal_effectif_row, axis=1)\n",
    "cap_base[\"MarketCap\"] = cap_base[\"Prix_Normal_Effectif\"] * cap_base[\"nb_actions_estime\"]\n",
    "\n",
    "# =======================\n",
    "# DÉTECTION & CLASSIFICATION DES ÉVÉNEMENTS (sur paliers snappés)\n",
    "# =======================\n",
    "def classify_event(is_simple, cap_change):\n",
    "    if pd.isna(cap_change):\n",
    "        return (\"Split/Regroupement\" if is_simple else \"Augmentation/Autre\",\n",
    "                0.6 if is_simple else 0.6,\n",
    "                \"Données cap insuffisantes; décision basée sur p:q uniquement\")\n",
    "    if is_simple and abs(cap_change) <= CAP_TOL:\n",
    "        return (\"Split/Regroupement\", 0.9, \"Ratio simple p:q et capitalisation ~inchangée\")\n",
    "    if (not is_simple) and (abs(cap_change) > CAP_TOL):\n",
    "        return (\"Augmentation/Autre\", 0.85, \"Ratio non simple et capitalisation change significativement\")\n",
    "    if is_simple:\n",
    "        return (\"Split/Regroupement\", 0.7, \"Ratio simple p:q mais variation cap ambiguë\")\n",
    "    else:\n",
    "        return (\"Augmentation/Autre\", 0.7, \"Ratio non simple mais variation cap ambiguë\")\n",
    "\n",
    "events = []\n",
    "for tik, g in ratio_snapped.groupby(\"Ticker\"):\n",
    "    g = g.sort_values(\"Date\").reset_index(drop=True).copy()\n",
    "    if g.empty:\n",
    "        continue\n",
    "    # changement quand le palier snappé change (vrai step)\n",
    "    g[\"snap_shift\"] = g[\"ratio_norm_snapped\"].shift(1)\n",
    "    change_mask = (g[\"ratio_norm_snapped\"].notna() & g[\"snap_shift\"].notna() &\n",
    "                   (g[\"ratio_norm_snapped\"] != g[\"snap_shift\"]))\n",
    "    idxs = g.index[change_mask].tolist()\n",
    "\n",
    "    # récup cap pour ce ticker\n",
    "    gb = cap_base[cap_base[\"Ticker\"] == tik].sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "    for idx in idxs:\n",
    "        date_evt = g.loc[idx, \"Date\"]\n",
    "        r_prev = g.loc[idx-1, \"ratio_norm_snapped\"]\n",
    "        r_now  = g.loc[idx, \"ratio_norm_snapped\"]\n",
    "        if not (pd.notna(r_prev) and pd.notna(r_now) and r_prev > 0):\n",
    "            continue\n",
    "        ratio_event = r_now / r_prev\n",
    "\n",
    "        p,q,xhat,is_simple = approx_simple_ratio(ratio_event, tol=RATIONAL_TOL, max_den=MAX_DENOM)\n",
    "\n",
    "        pre = gb[(gb[\"Date\"] < date_evt) & gb[\"MarketCap\"].notna()].tail(WINDOW)\n",
    "        post = gb[(gb[\"Date\"] > date_evt) & gb[\"MarketCap\"].notna()].head(WINDOW)\n",
    "        cap_pre = pre[\"MarketCap\"].median() if not pre.empty else np.nan\n",
    "        cap_post = post[\"MarketCap\"].median() if not post.empty else np.nan\n",
    "        cap_change = (cap_post - cap_pre) / cap_pre if (pd.notna(cap_pre) and cap_pre != 0 and pd.notna(cap_post)) else np.nan\n",
    "\n",
    "        decision, conf, reason = classify_event(is_simple, cap_change)\n",
    "\n",
    "        events.append({\n",
    "            \"Ticker\": tik,\n",
    "            \"Date_Changement\": date_evt.date(),\n",
    "            \"Ratio_Event\": ratio_event,\n",
    "            \"k_pq\": (f\"{p}:{q}\" if (p and q) else \"\"),\n",
    "            \"cap_pre\": cap_pre,\n",
    "            \"cap_post\": cap_post,\n",
    "            \"cap_change_pct\": cap_change,\n",
    "            \"Decision\": decision,\n",
    "            \"Confidence\": round(conf, 2),\n",
    "            \"Reason\": reason\n",
    "        })\n",
    "\n",
    "df_events = pd.DataFrame(events).sort_values([\"Ticker\",\"Date_Changement\"]) if events else pd.DataFrame(\n",
    "    columns=[\"Ticker\",\"Date_Changement\",\"Ratio_Event\",\"k_pq\",\"cap_pre\",\"cap_post\",\"cap_change_pct\",\"Decision\",\"Confidence\",\"Reason\"]\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# EXPORTS ANALYTIQUES\n",
    "# =======================\n",
    "out_daily = ratio_snapped[[\"Ticker\",\"Date\"]].merge(\n",
    "    df_all[[\"Ticker\",\"Date\",\"nb_actions_estime\",\"ratio_norm_snapped\"]], on=[\"Ticker\",\"Date\"], how=\"left\"\n",
    ").sort_values([\"Ticker\",\"Date\"])\n",
    "out_daily.to_csv(OUTPUT_SHARES_DAILY, index=False)\n",
    "df_events.to_csv(OUTPUT_EVENTS, index=False)\n",
    "print(f\"✅ Écrit: {OUTPUT_SHARES_DAILY}\")\n",
    "print(f\"✅ Écrit: {OUTPUT_EVENTS}\")\n",
    "\n",
    "# =======================\n",
    "# ENRICHI: + nb_actions_estime + Capitalisation\n",
    "# =======================\n",
    "# On repart du CSV d'origine pour garder les noms des colonnes originaux\n",
    "enriched = pd.read_csv(INPUT_PRICES_CSV)\n",
    "# Trouver noms originaux Ticker/Date\n",
    "ticker_orig = None\n",
    "date_orig = None\n",
    "for c in enriched.columns:\n",
    "    cl = c.strip().lower()\n",
    "    if cl in col_map_candidates[\"ticker\"] and ticker_orig is None:\n",
    "        ticker_orig = c\n",
    "    if cl in col_map_candidates[\"date\"] and date_orig is None:\n",
    "        date_orig = c\n",
    "if ticker_orig is None or date_orig is None:\n",
    "    raise ValueError(\"Impossible d'identifier les colonnes Ticker/Date dans le fichier source pour l'enrichissement final.\")\n",
    "\n",
    "tmp_merge = enriched[[ticker_orig, date_orig]].copy()\n",
    "tmp_merge = tmp_merge.rename(columns={ticker_orig:\"Ticker_raw\", date_orig:\"Date\"})\n",
    "tmp_merge[\"_Ticker_norm\"] = tmp_merge[\"Ticker_raw\"].apply(normalize_ticker)\n",
    "tmp_merge[\"Date\"] = pd.to_datetime(tmp_merge[\"Date\"], errors=\"coerce\")\n",
    "\n",
    "# joindre nb_actions_estime (snappé) + ratio brut + prix pour proxy\n",
    "tmp_merge = tmp_merge.merge(out_daily.rename(columns={\"Ticker\":\"_Ticker_norm\"}), on=[\"_Ticker_norm\",\"Date\"], how=\"left\")\n",
    "ratio_raw_daily = pr_daily.rename(columns={\"Ticker\":\"_Ticker_norm\"})\n",
    "tmp_merge = tmp_merge.merge(ratio_raw_daily[[\"_Ticker_norm\",\"Date\",\"ratio\",\"Cours_Ajuste\",\"Cours_Normal\"]],\n",
    "                            on=[\"_Ticker_norm\",\"Date\"], how=\"left\")\n",
    "\n",
    "def prix_normal_effectif_final(row):\n",
    "    cn = row.get(\"Cours_Normal\", np.nan)\n",
    "    ca = row.get(\"Cours_Ajuste\", np.nan)\n",
    "    r  = row.get(\"ratio\", np.nan)\n",
    "    if pd.notna(cn) and np.isfinite(cn) and cn > 0:\n",
    "        return cn\n",
    "    if pd.notna(ca) and np.isfinite(ca) and ca > 0 and pd.notna(r) and np.isfinite(r) and r > 0:\n",
    "        return ca * r\n",
    "    return np.nan\n",
    "\n",
    "tmp_merge[\"Prix_Normal_Effectif\"] = tmp_merge.apply(prix_normal_effectif_final, axis=1)\n",
    "tmp_merge[\"Capitalisation\"] = tmp_merge[\"Prix_Normal_Effectif\"] * tmp_merge[\"nb_actions_estime\"]\n",
    "\n",
    "# injecter dans la table d'origine\n",
    "enriched[\"nb_actions_estime\"] = tmp_merge[\"nb_actions_estime\"].values\n",
    "enriched[\"Capitalisation\"] = tmp_merge[\"Capitalisation\"].values\n",
    "\n",
    "# tri final: par ticker puis date décroissante\n",
    "enriched[date_orig] = pd.to_datetime(enriched[date_orig], errors=\"coerce\")\n",
    "enriched = enriched.sort_values([ticker_orig, date_orig], ascending=[True, False])\n",
    "# format date lisible (optionnel)\n",
    "enriched[date_orig] = enriched[date_orig].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "enriched.to_csv(OUTPUT_ENRICHED, index=False)\n",
    "print(f\"✅ Écrit: {OUTPUT_ENRICHED} (tri par ticker, dates décroissantes)\")\n",
    "\n",
    "# APERÇUS\n",
    "print(\"\\nAperçu événements (top 10):\")\n",
    "print(df_events.head(50))\n",
    "print(\"\\nAperçu historique (top 10):\")\n",
    "print(out_daily.head(50))\n",
    "print(\"\\nAperçu enriched (top 5):\")\n",
    "print(enriched.head(50))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
